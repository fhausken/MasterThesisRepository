
R version 3.3.3 (2017-03-06) -- "Another Canoe"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> rm(list=ls()) #Clears environment
> 
> library(parallel)
> library(doParallel)
Loading required package: foreach
Loading required package: iterators
> library(quantmod)
Loading required package: xts
Loading required package: zoo

Attaching package: 'zoo'

The following objects are masked from 'package:base':

    as.Date, as.Date.numeric

Loading required package: TTR
Version 0.4-0 included new data defaults. See ?getSymbols.
> library(lattice)
> library(timeSeries)
Loading required package: timeDate

Attaching package: 'timeSeries'

The following object is masked from 'package:zoo':

    time<-

> library(rugarch)

Attaching package: 'rugarch'

The following object is masked from 'package:stats':

    sigma

Warning messages:
1: In rgl.init(initValue, onlyNULL) : RGL: unable to open X11 display
2: 'rgl_init' failed, running with rgl.useNULL = TRUE 
> library(xts)
> library(tseries)
> 
> 
> no_cores=detectCores()
> c1=makeCluster(no_cores)
> registerDoParallel(c1)
> 
> 
> URL.repo=getwd()
> 
> URL.logging=paste(URL.repo,"/Output/ParallellLog_NewParallell.txt", sep="")
> cat("Output:\n\n", file=URL.logging, append=FALSE) #Clears log
> 
> URL=paste(URL.repo,"/Data/stockReturns.Rda",sep="")
> load(URL)
> 
> URL=paste(URL.repo,"/Data/stocks.Rda",sep="")
> load(URL)
> 
> URL=paste(URL.repo,"/Data/stocksRemoved.Rda",sep="")
> load(URL)
> 
> URL=paste(URL.repo,"/Data/distributionFitResults.Rda",sep="")
> load(URL)
> 
> sampleSizes=c(250,500)#,500,750,1000)
> garchModels=c('gjrGARCH','eGARCH')
> ARLag.max=2
> MALag.max=2
> GARCHLagOne.max=1
> GARCHLagTwo.max=1
> 
> 
> start_time <- Sys.time()
> allStocksResults=list()
> #allStocksResults=foreach(stocksIndex=1:nrow(stocks)) %dopar%{
> for (stocksIndex in 1:nrow(stocks)){
+   
+   
+   
+   
+   individualStockRetun=stockReturns[,stocksIndex]
+   stockDistribution=distributionsFitResults[stocksIndex,12]
+   stockDistribution.fullname=distributionsFitResults[stocksIndex,11]
+   
+   sampleSizeResults=list()
+   for (sampleSizesIndex in 1:length(sampleSizes)){
+     sampleSize = sampleSizes[sampleSizesIndex]
+     rollingWindowSize = length(individualStockRetun) - sampleSize
+     
+     print(paste(Sys.time(), "\t","Starting iteration: ",stocksIndex,"/" , nrow(stocks),". Stock: ",stocks[stocksIndex,1] ,". Sample size: ",sampleSize," \n",sep=""))
+     cat(paste(Sys.time(), "\t","Starting iteration: ",stocksIndex,"/" , nrow(stocks),". Stock: ",stocks[stocksIndex,1] ,". Sample size: ",sampleSize," \n",sep=""), file=URL.logging, append=TRUE)
+     #individualStockResults=list()
+     #for (day in 0:rollingWindowSize){
+     individualStockResults=foreach(day=0:rollingWindowSize) %dopar%{
+       library(parallel)
+       library(doParallel)
+       library(quantmod)
+       library(lattice)
+       library(timeSeries)
+       library(rugarch)
+       library(xts)
+       library(tseries)
+       
+       
+       
+       
+       individualStockReturnOffset = individualStockRetun[(1+day):(sampleSize+day)]
+     
+       AIC.final=1000000 # tilsvarer + infinity
+       
+       
+       for (garchModelsIndex in 1:length(garchModels)){
+         garchModel=garchModels[garchModelsIndex]
+         
+         for (ARLag in 0:ARLag.max){
+           for (MALag in 0:MALag.max){
+             for (GARCHLagOne in 0:GARCHLagOne.max){
+               for (GARCHLagTwo in 0:GARCHLagTwo.max){
+                 spec = ugarchspec(
+                   variance.model=list(model=garchModel,garchOrder=c(GARCHLagOne,GARCHLagTwo)),
+                   mean.model=list(armaOrder=c(ARLag, MALag), include.mean=T),
+                   distribution.model=stockDistribution
+                 )
+                 fit = tryCatch(
+                   ugarchfit(spec, individualStockReturnOffset, solver = 'hybrid'), error=function(e) e, warning=function(w) w
+                 )
+                 
+                 if(is(fit,"warning")){
+                   
+                   AIC=1000000
+                   #cat(paste(Sys.time(), "\t","Iteration: ",stocksIndex,"/" , nrow(stocks),". Stock: ",stocks[stocksIndex,1] ,". Sample size: ",sampleSize,". Day: ",day,"/" , rollingWindowSize,". Model: ",garchModel,ARLag,MALag,GARCHLagOne,GARCHLagTwo,". Warning i fit!","\n",sep=""), file=URL.logging, append=TRUE)
+                   
+                 } else if(is(fit," error")){
+                   
+                   AIC=1000000
+                   cat(paste(Sys.time(), "\t","Iteration: ",stocksIndex,"/" , nrow(stocks),". Stock: ",stocks[stocksIndex,1] ,". Sample size: ",sampleSize,". Day: ",day,"/" , rollingWindowSize, ". Model: ",garchModel,ARLag,MALag,GARCHLagOne,GARCHLagTwo,". Error i fit!","\n",sep=""), file=URL.logging, append=TRUE)
+                   
+                 }else{
+                   
+                   tryCatch({
+                     AIC=infocriteria(fit)[1]
+                     forecast=ugarchforecast(fit,n.ahead=1)
+                     forecastOneDayAhead=drop(forecast@forecast$seriesFor) #Drop fjerner kolonne og radnavn}
+                     }, error = function(e) { 
+                       cat(paste(Sys.time(), "\t","Iteration: ",stocksIndex,"/" , nrow(stocks),". Stock: ",stocks[stocksIndex,1] ,". Sample size: ",sampleSize,". Day: ",day,"/" , rollingWindowSize,". Model: ",garchModel,ARLag,MALag,GARCHLagOne,GARCHLagTwo,". Error i infocriteria!","\n",sep=""), file=URL.logging, append=TRUE)
+                       URL=paste(URL.repo,"/Data/ErroriFit.Rda",sep="")
+                       save(fit,file=URL)
+                       URL=paste(URL.repo,"/Data/ErroriSpec.Rda",sep="")
+                       save(spec,file=URL)
+                       
+                       AIC=1000000
+                     })
+                   
+                   
+                   
+                 }
+                 
+                 if (AIC<AIC.final){
+                   AIC.final=AIC
+                   forecastOneDayAhead.final=forecastOneDayAhead
+                   ARLag.final=ARLag
+                   MALag.final=MALag
+                   GARCHLagOne.final=GARCHLagOne
+                   GARCHLagTwo.final=GARCHLagTwo
+                   
+                   
+                 }
+                 
+               } 
+               
+             }
+             
+           }
+           
+         }
+         
+ 
+       }
+       if (AIC.final==1000000){
+         cat(paste(Sys.time(), "\t","Iteration: ",stocksIndex,"/" , nrow(stocks),". Stock: ",stocks[stocksIndex,1],". Sample size: ",sampleSize ,". Day: ",day,"/" , rollingWindowSize,". Did Not Converge!"," \n",sep=""), file=URL.logging, append=TRUE)
+         AIC=NULL
+         forecastOneDayAhead.final=NULL
+         garchModel=NULL
+         ARLag.final=NULL
+         MALag.final=NULL
+         GARCHLagOne.final=NULL
+         GARCHLagTwo.final=NULL
+         stockDistribution.fullname=NULL
+       }else{
+         if(GARCHLagOne.final==0){
+           if(GARCHLagTwo.final==0){
+             garchModel="Plain Vanilla ARMA" #Hvis vi bare har en ARMA prosess
+           }
+         }
+       }
+       
+       results=list(AIC.final, forecastOneDayAhead.final, garchModel,ARLag.final, MALag.final, GARCHLagOne.final, GARCHLagTwo.final, stockDistribution.fullname) # Merk at man må bruke to brackets for å legge til en liste inni en liste
+       names(results)=c("AIC", "One-Day-Ahead Forecast",  "Garch Model","AR Lag","MA Lag", "GARCH Lag 1","GARCH Lag 2","Stock Distribution" )
+       #individualStockResults[[length(individualStockResults)+1]]=results
+       return(results)
+       
+     }
+     names(individualStockResults)=index(individualStockRetun)[sampleSize:nrow(individualStockRetun)]
+     sampleSizeResults[[length(sampleSizeResults)+1]]=individualStockResults
+     
+     
+   }
+   
+   names(sampleSizeResults)=sampleSizes
+   allStocksResults[[length(allStocksResults)+1]]=sampleSizeResults
+   #return(sampleSizeResults)
+ }
[1] "2018-02-23 18:02:13\tStarting iteration: 1/6. Stock: DNB. Sample size: 250 \n"
[1] "2018-02-23 19:11:20\tStarting iteration: 1/6. Stock: DNB. Sample size: 500 \n"
[1] "2018-02-23 19:51:02\tStarting iteration: 2/6. Stock: Norsk Hydro. Sample size: 250 \n"
